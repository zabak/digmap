LGTE version 1.1.8

Release Notes:

VERY IMPORTANT NOTE
1 - One perfomance issue was detected when using MultiIndexes with previously opened IndexReaders using the lucene interface
    IndexReaders should be opened with The LgteIndexManager in order to read the index Cache values from files

    It is strongly recomended to do like this example:

    Map<String,IndexReader> readers = new HashMap<String,IndexReader>();
    IndexReader readerContents = LgteIndexManager.openReader("/indexes/test", Model.OkapiBM25Model);
    readers.put("contents",readerContents);
    return new LgteIndexSearcherWrapper(Model.OkapiBM25Model,new LgteIsolatedIndexReader(readers));

2 - New Properties at app.properties

    lgte.indexReader.cache.use.cache.for.docField.len=true  - (just require one extra int (2 bytes) in memory for each doc in index)
    cache.use.global_vars.cache=true - this property comes from 1.1.3 (does not require any extra memory just a few bytes for collection measures)
    index.tree=false - For index Trees, this property if configurable at queryConfiguration level see point 4 in this list

3 - New class DataCacher for pairs <LuceneDocId, CollectionDocId>. These pairs are alays created at index folders (file docid.cache)
    By default these files are not loaded into Lgte caches, you need to create it by hand choosing an index to load them taking into
    account htat all indexes have this file.

    This should be done to increase the speed of generating RUNS because you will need the Identifier Field that you saved in Document
    If you access to field("id") with document API ( lgteHits.document(i).get("id")) you will make Lgte to load the entire set of fields
    stored for that document. For that reason it is recomendended to use the DataCacher:
    (e.g.)
    pt.utl.ist.lucene.utils.DataCacher dataCacher = new pt.utl.ist.lucene.utils.DataCacher();
    dataCacher.loadFromFile("/indexes/contentsIndex/docid.cache",true);
    Obtaining the id's when iterating lgteHits:
    dataCacher.get("docid",lgteHits.id(i));

4 - Lgte support Hierarchic Indexes. See this example
    /*******************************************************************************************************/
    /**
     *  example:
     *    contents > sentences (doc_id)
     *
     *    Fields contents and sentences using two diferente indexes with a diferent set of id's
     *    Restriction: The Indexes should be created with the same sequence of DOCS.
     *    contents:  DOC_1                    DOC_2            DOC_3
     *    sentences: DOC_1_1 DOC_1_2 DOC_1_3  DOC_2_1 DOC_2_3  DOC_3_1 DOC_3_2
     *
     *    Using this configuration the query:  sentences:(w1 w2) contents(w1 w2)
     *    will map the scores from documents to sentences in order to show a resultSet in sentences space
     *
     * @param parent parent Index
     * @param child child Index
     * @param foreignKeyFieldChild2Parent field in child with the foreignkey to id field in parent
     *
     */
    

       Example: to see the complete example go here
       http://code.google.com/p/digmap/source/browse/trunk/LuceneGeoTemporal/WEB-INF/classes/pt/utl/ist/lucene/test/hierarchicindexes/OnlyAnExample.java

        /***********************************/
        /*******CREATING INDEXES CODE*******/
        /***********************************/

        String sentence1_1 = "word1 word2 word3 word32 word1 word45 word56 word67 word67 word2 word67 word88 word99 word99 word33";
        String sentence1_2 = "word2 word3 word4 word55 word96 word2 word54 word33 wordss";
        String sentence1_3 = "word1 word100 word400 word555 word966 word544 word333 wordss";
        String document1 = sentence1_1 + " " + sentence1_2 + " " + sentence1_3;


        String sentence2_1 = "word5 word67 word67";
        String sentence2_2 = "word6 word3 word44";
        String sentence2_3 = "word555 word966 word1000";
        String document2 = sentence2_1 + " " + sentence2_2 + " " + sentence2_3;

        //DOCS INDEX
        LgteIndexWriter writerDocs = new LgteIndexWriter(pathDocuments,true);

        LgteDocumentWrapper doc1 = new LgteDocumentWrapper();
        doc1.indexText(Globals.DOCUMENT_ID_FIELD, "1");
        doc1.indexText("contents",document1);

        LgteDocumentWrapper doc2 = new LgteDocumentWrapper();
        doc2.indexText(Globals.DOCUMENT_ID_FIELD, "2");
        doc2.indexText("contents",document2);

        writerDocs.addDocument(doc1);
        writerDocs.addDocument(doc2);
        writerDocs.close();



        //SENTENCES INDEX
        LgteIndexWriter writerSentences = new LgteIndexWriter(pathSentences,true);

        LgteDocumentWrapper stmVirtualDoc1_1 = new LgteDocumentWrapper();
        stmVirtualDoc1_1.indexText(Globals.DOCUMENT_ID_FIELD, "1_1");
        stmVirtualDoc1_1.indexText("doc_id", "1");
        stmVirtualDoc1_1.indexText("sentences",sentence1_1);

        LgteDocumentWrapper stmVirtualDoc1_2 = new LgteDocumentWrapper();
        stmVirtualDoc1_2.indexText(Globals.DOCUMENT_ID_FIELD, "1_2");
        stmVirtualDoc1_2.indexText("doc_id", "1");
        stmVirtualDoc1_2.indexText("sentences",sentence1_2);

        LgteDocumentWrapper stmVirtualDoc1_3 = new LgteDocumentWrapper();
        stmVirtualDoc1_3.indexText(Globals.DOCUMENT_ID_FIELD, "1_3");
        stmVirtualDoc1_3.indexText("doc_id", "1");
        stmVirtualDoc1_3.indexText("sentences",sentence1_3);

        LgteDocumentWrapper stmVirtualDoc2_1 = new LgteDocumentWrapper();
        stmVirtualDoc2_1.indexText(Globals.DOCUMENT_ID_FIELD, "2_1");
        stmVirtualDoc2_1.indexText("doc_id", "2");
        stmVirtualDoc2_1.indexText("sentences",sentence2_1);

        LgteDocumentWrapper stmVirtualDoc2_2 = new LgteDocumentWrapper();
        stmVirtualDoc2_2.indexText(Globals.DOCUMENT_ID_FIELD, "2_2");
        stmVirtualDoc2_2.indexText("doc_id", "2");
        stmVirtualDoc2_2.indexText("sentences",sentence2_2);

        LgteDocumentWrapper stmVirtualDoc2_3 = new LgteDocumentWrapper();
        stmVirtualDoc2_3.indexText(Globals.DOCUMENT_ID_FIELD, "2_3");
        stmVirtualDoc2_3.indexText("doc_id", "2");
        stmVirtualDoc2_3.indexText("sentences",sentence2_3);

        writerSentences.addDocument(stmVirtualDoc1_1);
        writerSentences.addDocument(stmVirtualDoc1_2);
        writerSentences.addDocument(stmVirtualDoc1_3);
        writerSentences.addDocument(stmVirtualDoc2_1);
        writerSentences.addDocument(stmVirtualDoc2_2);
        writerSentences.addDocument(stmVirtualDoc2_3);

        writerSentences.close();

        writerSentences.close();


        /*******************************/
        /******** SEARCH CODE *********/
        /******************************/

        IndexReader readerDocs = LgteIndexManager.openReader(pathDocuments, Model.OkapiBM25Model);
        IndexReader readerSentences = LgteIndexManager.openReader(pathSentences,Model.OkapiBM25Model);

        Map<String,IndexReader> readers = new HashMap<String,IndexReader>();
        readers.put("contents",readerDocs);
        readers.put("sentences",readerSentences);
        readers.put("doc_id",readerSentences);
        readers.put("id",readerSentences);
        LgteIsolatedIndexReader lgteIsolatedIndexReader = new LgteIsolatedIndexReader(readers);
        lgteIsolatedIndexReader.addTreeMapping(readerDocs,readerSentences,"doc_id");

        LgteIndexSearcherWrapper searcher = new LgteIndexSearcherWrapper(Model.OkapiBM25Model,lgteIsolatedIndexReader);
        QueryConfiguration queryConfiguration = new QueryConfiguration();
        queryConfiguration.setProperty("bm25.idf.policy","floor_epslon");
        queryConfiguration.setProperty("bm25.idf.epslon","0.05");
        queryConfiguration.setProperty("bm25.k1","2.0d");
        queryConfiguration.setProperty("bm25.b","0.75d");
        queryConfiguration.setProperty("index.tree","true");    //only needed for fields used in score functions

        LgteQuery lgteQuery = LgteQueryParser.parseQuery("contents:(word1 word2 word3)^0.3 sentences:(word1 word2 word3)^0.7",searcher,queryConfiguration);
        LgteHits lgteHits = searcher.search(lgteQuery);
        System.out.println("SCHEME 0.7*score(Sentence) + (0.3)*score(contents)");
        System.out.println("Sentence " + lgteHits.doc(0).get("id") + ":" + lgteHits.doc(0).get("doc_id") + " (0.7*stm1 + 0.3*doc1):" + lgteHits.score(0));
        System.out.println("Sentence " + lgteHits.doc(1).get("id") + ":" + lgteHits.doc(1).get("doc_id") + " (0.7*stm2 + 0.3*doc1):" + lgteHits.score(1));
        System.out.println("Sentence " + lgteHits.doc(2).get("id") + ":" + lgteHits.doc(2).get("doc_id") + " (0.7*stm3 + 0.3*doc1):" + lgteHits.score(2));
        System.out.println("Sentence " + lgteHits.doc(3).get("id") + ":" + lgteHits.doc(3).get("doc_id") + " (0.7*stm5 + 0.3*doc2):" + lgteHits.score(3));

        /*******************************************************************************************************/

5 - Increased the number of Buffered docs in lucene Hits class to 2000 because sentences queries are very slow in order to lucene do only one iteraction in index to retrieve results 

Lgte Implementation Details

1 - When running several tests together in the same JVM cache values like collection size were being used in wrong contexts
    To solve the problem DataCacher form ILPS is not used anymore. Now each Reader has it's own dataCacher active only
      during the Reader lifeCycle

2 - LgteIndexSearcherManager was renamed to LgteIndexManager
3 - Probabilistic Reader added to refactor the probabilities caches
4 - DataCacher from ilps not in use.
5 - Was created one DataCacher for each IndexReader in LgteIsolatedReader for MultiIndexes
6 - At TermScorerLanguageModel and TermScorerDFR constructors the call to LanguageModelIndexReader constructor was changed
    Now the given Reader is a ProbabilisticIndexReader with the methods to access the cache values
7 - Several LGTE instances could now be loaded in the same JVM once the caches are independent in each index

8 - ToDo  DOCID Mapping should be done only at one Reader - Need to be evaluated


